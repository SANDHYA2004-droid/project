console.log("âœ… Teams Monitor content.js loaded!");

let meetingStarted = false;
let startTime = null;
let recorder;
let chunks = [];
let recordingBar;
let timerInterval;

function log(msg) {
  console.log(`[Teams Monitor] ${msg}`);
}

function showRecordingBar() {
  if (recordingBar) return;

  recordingBar = document.createElement("div");
  recordingBar.style.position = "fixed";
  recordingBar.style.bottom = "20px";
  recordingBar.style.right = "20px";
  recordingBar.style.background = "red";
  recordingBar.style.color = "white";
  recordingBar.style.padding = "8px 12px";
  recordingBar.style.borderRadius = "8px";
  recordingBar.style.fontSize = "14px";
  recordingBar.style.zIndex = "999999";
  recordingBar.textContent = "âºï¸ Recording... 00:00";

  document.body.appendChild(recordingBar);

  let seconds = 0;
  timerInterval = setInterval(() => {
    seconds++;
    const m = String(Math.floor(seconds / 60)).padStart(2, "0");
    const s = String(seconds % 60).padStart(2, "0");
    recordingBar.textContent = `âºï¸ Recording... ${m}:${s}`;
  }, 1000);
}

function hideRecordingBar() {
  if (recordingBar) {
    recordingBar.remove();
    recordingBar = null;
  }
  clearInterval(timerInterval);
}

async function startRecording(mode) {
  if (mode === "none") {
    log("ðŸš« Recording disabled by user.");
    return;
  }

  try {
    let stream;
    if (mode === "audio") {
      stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    } else if (mode === "video") {
      stream = await navigator.mediaDevices.getDisplayMedia({ video: true });
    } else {
      stream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });
    }

    recorder = new MediaRecorder(stream);
    chunks = [];

    recorder.ondataavailable = (e) => chunks.push(e.data);

    recorder.onstop = () => {
      hideRecordingBar();
      if (chunks.length) {
        const blob = new Blob(chunks, { type: "video/webm" });
        const url = URL.createObjectURL(blob);
        const a = document.createElement("a");
        a.href = url;
        a.download = `meeting_${Date.now()}.webm`;
        a.click();
        URL.revokeObjectURL(url);
      }
    };

    recorder.start();
    showRecordingBar();
    log("â–¶ï¸ Recording started.");
  } catch (err) {
    console.error("âŒ Recording error:", err);
  }
}

function stopRecording() {
  if (recorder && recorder.state !== "inactive") {
    recorder.stop();
    log("â¹ï¸ Recording stopped.");
  }
  hideRecordingBar();
}

const observer = new MutationObserver(() => {
  const toolbar = document.querySelector('div[role="toolbar"][aria-label*="Meeting"]');

  if (toolbar && !meetingStarted) {
    meetingStarted = true;
    startTime = new Date();
    log(`Meeting started at: ${startTime.toLocaleString()}`);

    chrome.storage.local.get("recordMode", (data) => {
      const mode = data.recordMode || "audiovideo";
      startRecording(mode);
    });

    chrome.runtime.sendMessage({ type: "meeting-start", time: startTime.toLocaleTimeString() });
  } 
  else if (!toolbar && meetingStarted) {
    meetingStarted = false;
    const endTime = new Date();
    const durationSec = Math.round((endTime - startTime) / 1000);

    log(`Meeting ended at: ${endTime.toLocaleString()}`);
    log(`Duration: ${durationSec} seconds`);

    stopRecording();

    chrome.runtime.sendMessage({ type: "meeting-end", duration: durationSec });
  }
});

observer.observe(document.body, { childList: true, subtree: true });

log("Meeting monitor is running...");
